{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2e48d4a",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be4b83e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Check for available device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_built() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'lotka_volterra_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "df_scaled = scaler.fit_transform(df[['Prey', 'Predator']])\n",
    "\n",
    "# Convert the dataset to PyTorch tensors\n",
    "data = torch.FloatTensor(df_scaled).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38aa969c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_8/y_6h2y4d3yb0y40b3dr8mz140000gn/T/ipykernel_16033/1571261761.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m  \u001b[0;31m# number of previous time steps to consider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_inout_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_inout_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Define the RNN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/_8/y_6h2y4d3yb0y40b3dr8mz140000gn/T/ipykernel_16033/1571261761.py\u001b[0m in \u001b[0;36mcreate_inout_sequences\u001b[0;34m(input_data, tw)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minout_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtw\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0minout_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_seq\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+tw:i+tw+1]\n",
    "        inout_seq.append((train_seq, train_label))\n",
    "    return inout_seq\n",
    "\n",
    "seq_length = 5  # number of previous time steps to consider\n",
    "train_inout_seq = create_inout_sequences(data, seq_length)\n",
    "\n",
    "# Define the RNN model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_layer_size=10, output_size=2):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        # Using ReLU activation in RNN layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_layer_size, nonlinearity='relu')\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = torch.zeros(1,1,self.hidden_layer_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        rnn_out, self.hidden_cell = self.rnn(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(rnn_out.view(len(input_seq), -1))\n",
    "        \n",
    "        return predictions[-1]\n",
    "\n",
    "# Instantiate the model, define the loss function and the optimizer\n",
    "model = RNN().to(device)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cb1b98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training the RNN\n",
    "epochs = 20\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    for seq, labels in train_inout_seq:\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size).to(device))\n",
    "\n",
    "        y_pred = model(seq)\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    losses.append(single_loss.item())\n",
    "    \n",
    "    print(f'epoch: {i} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06686f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the learning curve\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.xticks(np.arange(0,20,1))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('RNN Learning Curve')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(\"Learning Curve.png\", dpi = 400)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cf135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.to('cpu')\n",
    "torch.save(model.state_dict(), 'ode_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcd9985",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Assuming the model and the scaler are already defined and trained\n",
    "\n",
    "# Load the test data\n",
    "test_df = pd.read_csv('lotka_volterra_data_test.csv')\n",
    "\n",
    "# Normalize the test data\n",
    "test_scaled = scaler.transform(test_df[['Prey', 'Predator']])\n",
    "test_data = torch.FloatTensor(test_scaled).to(device)\n",
    "\n",
    "# Prepare the test data sequences\n",
    "test_sequences = create_inout_sequences(test_data, seq_length)\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "test_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for seq, true_value in test_sequences:\n",
    "        seq = seq.to(device)\n",
    "        true_value = true_value.to(device)\n",
    "        prediction = model(seq)\n",
    "        test_loss += loss_function(prediction, true_value).item()\n",
    "\n",
    "test_loss /= len(test_sequences)\n",
    "print(f'Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4231b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the trends over time for the Lotka-Volterra model\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plotting prey and predator populations over time\n",
    "plt.plot(test_df['Time'], test_df['Prey'], label='Prey Population', color='blue')\n",
    "plt.plot(test_df['Time'], test_df['Predator'], label='Predator Population', color='orange')\n",
    "\n",
    "# Plot settings\n",
    "plt.title('Lotka-Volterra Model Trends Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Population')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfce7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "# Assuming the model and the scaler are already defined and trained\n",
    "\n",
    "# Load the test data\n",
    "test_df = pd.read_csv('lotka_volterra_data.csv')\n",
    "\n",
    "# Normalize the test data\n",
    "test_scaled = scaler.transform(test_df[['Prey', 'Predator']])\n",
    "test_data = torch.FloatTensor(test_scaled).to(device)\n",
    "\n",
    "# Prepare the test data sequences\n",
    "test_sequences = create_inout_sequences(test_data, seq_length)\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "model.to(device)\n",
    "\n",
    "test_loss = 0\n",
    "predictions = []  # Store model predictions\n",
    "\n",
    "with torch.no_grad():\n",
    "    for seq, true_value in test_sequences:\n",
    "        seq = seq.to(device)\n",
    "        true_value = true_value.to(device)\n",
    "        prediction = model(seq)\n",
    "        test_loss += loss_function(prediction, true_value).item()\n",
    "        predictions.append(prediction.cpu().numpy())  # Append predictions to the list\n",
    "\n",
    "test_loss /= len(test_sequences)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "\n",
    "# Reshape the predicted_data to a 2D array\n",
    "predicted_data = np.concatenate(predictions, axis=0).reshape(-1, 2)\n",
    "\n",
    "# Pad the beginning of predicted_data with NaN values to match the time values' length\n",
    "num_nan_values = len(test_df['Time']) - len(predicted_data)\n",
    "if num_nan_values > 0:\n",
    "    nan_values = np.full((num_nan_values, 2), np.nan)\n",
    "    predicted_data = np.concatenate([nan_values, predicted_data], axis=0)\n",
    "\n",
    "# Inverse-transform the scaled predictions back to the original scale\n",
    "predicted_data = scaler.inverse_transform(predicted_data)\n",
    "\n",
    "# Plotting the trends over time for the Lotka-Volterra model\n",
    "plt.figure(figsize=(12, 6))\n",
    "    \n",
    "# Plotting prey and predator populations over time\n",
    "plt.plot(test_df['Time'], test_df['Prey'], label='Prey Population', color='blue')\n",
    "plt.plot(test_df['Time'], test_df['Predator'], label='Predator Population', color='orange')\n",
    "\n",
    "# Plotting the model's predicted trend\n",
    "plt.plot(test_df['Time'], predicted_data[:, 0], label='Predicted Prey Population', linestyle='--', color='green')\n",
    "plt.plot(test_df['Time'], predicted_data[:, 1], label='Predicted Predator Population', linestyle='--', color='red')\n",
    "\n",
    "# Plot settings\n",
    "plt.title('Lotka-Volterra Model Trend Vs. RNN Predicted Trend')\n",
    "plt.ylim(0,55)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Population')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.grid(True)\n",
    "    \n",
    "plt.savefig(\"RNN Simulation Results.png\", dpi = 400)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f22c66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
